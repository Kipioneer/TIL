{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b300690d-8531-4713-b914-b7c76ce45945",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T01:37:26.137181Z",
     "iopub.status.busy": "2023-08-23T01:37:26.136392Z",
     "iopub.status.idle": "2023-08-23T01:37:35.798070Z",
     "shell.execute_reply": "2023-08-23T01:37:35.795741Z",
     "shell.execute_reply.started": "2023-08-23T01:37:26.137026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: http://repo.ai.gato/registry/repository/pypi-proxy/simple\n",
      "Requirement already satisfied: transformers in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (4.31.0)\n",
      "Requirement already satisfied: sentencepiece in /home/K2022508/.local/lib/python3.10/site-packages (0.1.99)\n",
      "Requirement already satisfied: filelock in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/gatoai/python/venv/jupyter-3.5.0-py3.10/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/gatoai/python/venv/jupyter-3.5.0-py3.10/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/gatoai/python/venv/jupyter-3.5.0-py3.10/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/gatoai/python/venv/3.10/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/gatoai/python/venv/jupyter-3.5.0-py3.10/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /usr/gatoai/python/venv/jupyter-3.5.0-py3.10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/gatoai/python/venv/jupyter-3.5.0-py3.10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/gatoai/python/venv/jupyter-3.5.0-py3.10/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/gatoai/python/venv/jupyter-3.5.0-py3.10/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/gatoai/python/venv/jupyter-3.5.0-py3.10/lib/python3.10/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/gatoai/python/venv/jupyter-3.5.0-py3.10/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e4e1f17-2645-42e7-874a-947ccbec506b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T01:40:04.602520Z",
     "iopub.status.busy": "2023-08-23T01:40:04.601468Z",
     "iopub.status.idle": "2023-08-23T01:50:59.941706Z",
     "shell.execute_reply": "2023-08-23T01:50:59.940078Z",
     "shell.execute_reply.started": "2023-08-23T01:40:04.602454Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f951877a3b8b4ec18ae3b73e9c48b3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813726d028ef4d419a634bce84b1b9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/5.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac6f86347df49c0b9c45e93bbaf5dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb334e241e54058a0d6802a293476dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2cc1596a5974d68a07b51593edd8fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0f037c7c7645f6ac3ae8863c08cbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "# 모델 및 토크나이저 불러오기\n",
    "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c26c87e8-a47c-4854-b926-2b9d8ef2641e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T02:04:29.260485Z",
     "iopub.status.busy": "2023-08-23T02:04:29.259622Z",
     "iopub.status.idle": "2023-08-23T02:04:29.279472Z",
     "shell.execute_reply": "2023-08-23T02:04:29.278054Z",
     "shell.execute_reply.started": "2023-08-23T02:04:29.260425Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   40, 16726,   262,  2854,   286,   402, 11571,    12,  8199,    78,\n",
      "         4166,   416,  4946, 20185,    13])\n",
      "I evaluated the performance of GPT-Neo developed by OpenAI.\n"
     ]
    }
   ],
   "source": [
    "# 텍스트=>정수 인코딩(1개의 문장)\n",
    "\n",
    "input = tokenizer.encode(\"I evaluated the performance of GPT-Neo developed by OpenAI.\", return_tensors=\"pt\")\n",
    "print(input[0])\n",
    "print(tokenizer.decode(input[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57e932d8-ceef-4288-aa2e-2b4f8292e488",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T02:04:36.243263Z",
     "iopub.status.busy": "2023-08-23T02:04:36.242417Z",
     "iopub.status.idle": "2023-08-23T02:04:36.256819Z",
     "shell.execute_reply": "2023-08-23T02:04:36.255437Z",
     "shell.execute_reply.started": "2023-08-23T02:04:36.243204Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   40, 16726,   262,  2854,   286,   402, 11571,    12,  8199,    78,\n",
      "          4166,   416,  4946, 20185,    13],\n",
      "        [   40, 16726,   262,  2854,   286,   402, 11571,  4166,   416,  4946,\n",
      "         20185,    13, 50257, 50257, 50257]])\n",
      "['I evaluated the performance of GPT-Neo developed by OpenAI.', 'I evaluated the performance of GPT developed by OpenAI. [PAD] [PAD] [PAD]']\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩(복수 문장)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "input = tokenizer.batch_encode_plus(\n",
    "    [\"I evaluated the performance of GPT-Neo developed by OpenAI.\",\n",
    "     \"I evaluated the performance of GPT developed by OpenAI.\"]\n",
    "     , padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "print(input['input_ids'])\n",
    "print([tokenizer.decode(input['input_ids'][i]) for i in range(len(input['input_ids']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f55d9f54-94f7-43bd-b626-532a886ad506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T02:05:11.604631Z",
     "iopub.status.busy": "2023-08-23T02:05:11.604001Z",
     "iopub.status.idle": "2023-08-23T02:05:11.614490Z",
     "shell.execute_reply": "2023-08-23T02:05:11.612882Z",
     "shell.execute_reply.started": "2023-08-23T02:05:11.604577Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 복수의 문장 인코딩\n",
    "input = tokenizer.batch_encode_plus(\n",
    "    [\"I evaluated the performance of GPT2 developed by OpenAI.\",\n",
    "     \"Vaccine for new coronavirus in the UK\",\n",
    "    \"3.1415926535\"]\n",
    "    , max_length=5, truncation=True, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef3d70ca-2a8c-495d-9ec5-33fcab8d3d59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T02:05:14.010940Z",
     "iopub.status.busy": "2023-08-23T02:05:14.010285Z",
     "iopub.status.idle": "2023-08-23T02:05:14.022534Z",
     "shell.execute_reply": "2023-08-23T02:05:14.020951Z",
     "shell.execute_reply.started": "2023-08-23T02:05:14.010884Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   40, 16726,   262,  2854,   286],\n",
       "        [   53,  4134,   500,   329,   649],\n",
       "        [   18,    13,  1415, 19707, 22980]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인코딩 결과 확인\n",
    "input['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce5b8f7f-29b5-4007-a63b-3a38408445b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T02:05:28.628813Z",
     "iopub.status.busy": "2023-08-23T02:05:28.628558Z",
     "iopub.status.idle": "2023-08-23T02:05:39.348015Z",
     "shell.execute_reply": "2023-08-23T02:05:39.346267Z",
     "shell.execute_reply.started": "2023-08-23T02:05:28.628790Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# 문장 만들기\n",
    "generated = model.generate(input['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca526713-6ef0-4a56-8e41-e07e5c567698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T02:05:40.913220Z",
     "iopub.status.busy": "2023-08-23T02:05:40.912376Z",
     "iopub.status.idle": "2023-08-23T02:05:40.923445Z",
     "shell.execute_reply": "2023-08-23T02:05:40.921819Z",
     "shell.execute_reply.started": "2023-08-23T02:05:40.913162Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.1\n",
      "I evaluated the performance of the proposed method on the real-world dataset. The results are shown in\n",
      "\n",
      "No.2\n",
      "Vaccine for new-borns\n",
      "\n",
      "The vaccine for new-borns is a vaccine\n",
      "\n",
      "No.3\n",
      "3.1415926535897932384626433832795028841971693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 생성된 문장 디코딩\n",
    "generated_text = tokenizer.batch_decode(generated)\n",
    "for i, sentence in enumerate(generated_text):\n",
    "  print(f'No.{i+1}')\n",
    "  print(f\"{sentence}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffe678bb-72f7-43c9-bc5f-c0f3d626113e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T02:06:30.437663Z",
     "iopub.status.busy": "2023-08-23T02:06:30.437030Z",
     "iopub.status.idle": "2023-08-23T02:07:36.979933Z",
     "shell.execute_reply": "2023-08-23T02:07:36.977733Z",
     "shell.execute_reply.started": "2023-08-23T02:06:30.437609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea03dbd013a74bd98d6ba17a55fbccf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932c8de199954a9997f4a749efd4f94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0a6740cce349fda64e11b44801d447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5cdaf706114bfea7c0e9576e409792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a57bf1d36f846e2a02a60962149e7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50323a34cbc4814ab12ca4e2655779a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DistilGPT2 모형 활용\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6805ac4b-a75f-4078-b993-58ddb7a5e8e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T02:15:12.976132Z",
     "iopub.status.busy": "2023-08-23T02:15:12.975296Z",
     "iopub.status.idle": "2023-08-23T02:15:13.556918Z",
     "shell.execute_reply": "2023-08-23T02:15:13.555885Z",
     "shell.execute_reply.started": "2023-08-23T02:15:12.976075Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I like gpt because it's a good thing to have a good friend.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DistilGPT2 모형으로 문장 만들기\n",
    "input_ids = tokenizer.encode(\"I like gpt because it's\", return_tensors='pt')\n",
    "greedy_output = model.generate(input_ids, max_length=12)\n",
    "greedy_output = model.generate(input_ids, max_length=20)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44304e3-0a37-4d8f-ae6e-ed421318270d",
   "metadata": {},
   "source": [
    "### DialoGPT 모형 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0a2f520-bad3-45a6-8262-3e883628037b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T02:18:07.854525Z",
     "iopub.status.busy": "2023-08-23T02:18:07.853870Z",
     "iopub.status.idle": "2023-08-23T02:18:52.903999Z",
     "shell.execute_reply": "2023-08-23T02:18:52.902516Z",
     "shell.execute_reply.started": "2023-08-23T02:18:07.854465Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f2baf6ba314c21a4a72c8d04e61439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/351M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ede5a876d554d389e8559f61f8f9ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('microsoft/DialoGPT-small')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9943bd5-d785-4b39-b00a-6d151cf81c17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T02:38:52.406097Z",
     "iopub.status.busy": "2023-08-23T02:38:52.405457Z",
     "iopub.status.idle": "2023-08-23T02:38:54.521357Z",
     "shell.execute_reply": "2023-08-23T02:38:54.520473Z",
     "shell.execute_reply.started": "2023-08-23T02:38:52.406043Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I like gpt because it's a good way to get a feel for the game.\n"
     ]
    }
   ],
   "source": [
    "#문장 만들기\n",
    "input_ids = tokenizer.encode(\"I like gpt because it's\", return_tensors='pt')\n",
    "greedy_output = model.generate(input_ids, max_length=30)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))\n",
    "\n",
    "#좀더 자연스러운 문장이 만들어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a0ee182-53db-41ec-a725-570c3641cc82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T02:42:11.207651Z",
     "iopub.status.busy": "2023-08-23T02:42:11.207022Z",
     "iopub.status.idle": "2023-08-23T02:42:11.513011Z",
     "shell.execute_reply": "2023-08-23T02:42:11.511824Z",
     "shell.execute_reply.started": "2023-08-23T02:42:11.207596Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Covid19 delta is spreading the word\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\"Covid19 delta is spreading\", return_tensors='pt')\n",
    "# greedy_output = model.generate(input_ids, max_length=10)\n",
    "greedy_output = model.generate(input_ids, max_length=20)\n",
    "\n",
    "print(\"Outputs:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e7a424a-8cb8-41a3-a21f-11596dfa1e45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T02:44:35.662753Z",
     "iopub.status.busy": "2023-08-23T02:44:35.662091Z",
     "iopub.status.idle": "2023-08-23T02:45:41.053404Z",
     "shell.execute_reply": "2023-08-23T02:45:41.051635Z",
     "shell.execute_reply.started": "2023-08-23T02:44:35.662683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928078e3c7be44398259f3ff80e91530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63b12382d444a30bdba1c1f1ecd3104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83feca3bf6394f41ba8368c495a54d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d0f8396f0043e59c27a4b79f331e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7ac84d919c43f28d6945b7edc86f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1829015463590622,\n",
       "  'token': 2293,\n",
       "  'token_str': 'love',\n",
       "  'sequence': 'i love apple.'},\n",
       " {'score': 0.12624028325080872,\n",
       "  'token': 2066,\n",
       "  'token_str': 'like',\n",
       "  'sequence': 'i like apple.'},\n",
       " {'score': 0.11780295521020889,\n",
       "  'token': 2359,\n",
       "  'token_str': 'wanted',\n",
       "  'sequence': 'i wanted apple.'},\n",
       " {'score': 0.06842318177223206,\n",
       "  'token': 2215,\n",
       "  'token_str': 'want',\n",
       "  'sequence': 'i want apple.'},\n",
       " {'score': 0.055607497692108154,\n",
       "  'token': 3866,\n",
       "  'token_str': 'loved',\n",
       "  'sequence': 'i loved apple.'}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLM(Masked Language Model): 문서의 일부를 가리고(mask) 원래 단어를 추측하는 빈칸 채우기\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "\n",
    "# [Mask]가 포함된 문장 입력\n",
    "unmasker(\"I [MASK] apple.\")\n",
    "# [Mask] 위치에 입력될 수 있는 단어들을 추천하여 문장 완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36b06626-a55b-4584-8b8b-b4ccf5b9e731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T02:48:02.970858Z",
     "iopub.status.busy": "2023-08-23T02:48:02.970171Z",
     "iopub.status.idle": "2023-08-23T02:48:02.978171Z",
     "shell.execute_reply": "2023-08-23T02:48:02.976524Z",
     "shell.execute_reply.started": "2023-08-23T02:48:02.970796Z"
    }
   },
   "outputs": [],
   "source": [
    "# 제일 높게 출력된 단어 와 완성된 문장\n",
    "# 'token_str': 'loved',\n",
    "# 'sequence': 'i loved apple.'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d17cc470-1781-407d-9030-92c0a7f58e54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T02:50:37.353843Z",
     "iopub.status.busy": "2023-08-23T02:50:37.353142Z",
     "iopub.status.idle": "2023-08-23T02:50:39.359612Z",
     "shell.execute_reply": "2023-08-23T02:50:39.358185Z",
     "shell.execute_reply.started": "2023-08-23T02:50:37.353778Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.06269729137420654,\n",
       "  'token': 8823,\n",
       "  'token_str': 'ate',\n",
       "  'sequence': 'i ate apple.'},\n",
       " {'score': 0.05864424630999565,\n",
       "  'token': 2293,\n",
       "  'token_str': 'love',\n",
       "  'sequence': 'i love apple.'},\n",
       " {'score': 0.05670216679573059,\n",
       "  'token': 3866,\n",
       "  'token_str': 'loved',\n",
       "  'sequence': 'i loved apple.'},\n",
       " {'score': 0.05136874318122864,\n",
       "  'token': 6283,\n",
       "  'token_str': 'hated',\n",
       "  'sequence': 'i hated apple.'},\n",
       " {'score': 0.0491315983235836,\n",
       "  'token': 4521,\n",
       "  'token_str': 'eat',\n",
       "  'sequence': 'i eat apple.'}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# distilbert 모델\n",
    "unmasker = pipeline('fill-mask', model = 'distilbert-base-uncased')\n",
    "unmasker('I [MASK] apple.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e808a5d-2a54-4bfc-976a-b903bdf0da07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T02:51:13.737397Z",
     "iopub.status.busy": "2023-08-23T02:51:13.736704Z",
     "iopub.status.idle": "2023-08-23T02:51:13.744223Z",
     "shell.execute_reply": "2023-08-23T02:51:13.742661Z",
     "shell.execute_reply.started": "2023-08-23T02:51:13.737340Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모형에 따라 추천되는 단어가 달라짐\n",
    "# 'token_str': 'eat',\n",
    "# 'sequence': 'i eat apple.'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "46c44233-b1a0-45a2-bb7a-fcd586699fcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T02:53:15.395523Z",
     "iopub.status.busy": "2023-08-23T02:53:15.394837Z",
     "iopub.status.idle": "2023-08-23T02:53:15.932374Z",
     "shell.execute_reply": "2023-08-23T02:53:15.930785Z",
     "shell.execute_reply.started": "2023-08-23T02:53:15.395466Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForMaskedLM: ['albert.pooler.bias', 'albert.pooler.weight']\n",
      "- This IS expected if you are initializing AlbertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.12620007991790771,\n",
       "  'token': 339,\n",
       "  'token_str': 'love',\n",
       "  'sequence': 'i love apple.'},\n",
       " {'score': 0.0922037661075592,\n",
       "  'token': 3345,\n",
       "  'token_str': 'liked',\n",
       "  'sequence': 'i liked apple.'},\n",
       " {'score': 0.05626443028450012,\n",
       "  'token': 2199,\n",
       "  'token_str': 'loved',\n",
       "  'sequence': 'i loved apple.'},\n",
       " {'score': 0.04441851004958153,\n",
       "  'token': 5285,\n",
       "  'token_str': 'hated',\n",
       "  'sequence': 'i hated apple.'},\n",
       " {'score': 0.0399409718811512,\n",
       "  'token': 3223,\n",
       "  'token_str': 'hate',\n",
       "  'sequence': 'i hate apple.'}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# albert 모델: bert 모델의 정확도를 높이고 경량화한 모형\n",
    "unmasker = pipeline('fill-mask', model='albert-base-v2')\n",
    "unmasker('I [MASK] apple.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c99305a-043b-417b-a3cf-1dcbd289cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델마다 다른 결과\n",
    "# 'token_str': 'hate',\n",
    "# 'sequence': 'i hate apple.'}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
