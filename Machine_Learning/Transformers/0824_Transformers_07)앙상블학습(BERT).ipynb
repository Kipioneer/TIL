{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "앙상블 학습(BERT)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-08-24T12:51:44.278535Z",
     "end_time": "2023-08-24T12:51:44.306490Z"
    }
   },
   "outputs": [],
   "source": [
    "# 후속문장(이어지는 문장)이면 1, 아니면 0\n",
    "dataset = [[\"What music do you like?\", \"I like Rock music.\", 1],\n",
    "           [\"What is your favorite food?\", \"I like sushi the best\", 1],\n",
    "           [\"What is your favorite color?\", \"I'm going to be a doctor\", 0],\n",
    "           [\"What is your favorite song?\", \"Tokyo olympic game in 2020 was postponed\", 0],\n",
    "           [\"Do you like watching TV shows?\", \"Yeah, I often watch it in my spare time\", 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from transformers import BertPreTrainedModel, BertConfig, BertModel, BertTokenizer, AdamW\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "#앙상블 학습을 위한 클래스\n",
    "\n",
    "class BertEnsembleForNextSentencePrediction(BertPreTrainedModel):\n",
    "\n",
    "  def __init__(self, config, *args, **kwargs):\n",
    "\n",
    "      super().__init__(config)\n",
    "\n",
    "      # QA(Question, Answer) BERT 모델\n",
    "\n",
    "      self.bert_model_1 = BertModel(config)\n",
    "\n",
    "      # AQ(Answer, Question) BERT 모델\n",
    "\n",
    "      self.bert_model_2 = BertModel(config)\n",
    "\n",
    "      # 선형함수\n",
    "\n",
    "      self.cls = nn.Linear(2 * self.config.hidden_size, 2)\n",
    "\n",
    "      # 초기 가중치\n",
    "\n",
    "      self.init_weights()\n",
    "\n",
    "  def forward(\n",
    "\n",
    "          self,\n",
    "\n",
    "          input_ids=None,\n",
    "\n",
    "          attention_mask=None,\n",
    "\n",
    "          token_type_ids=None,\n",
    "\n",
    "          position_ids=None,\n",
    "\n",
    "          head_mask=None,\n",
    "\n",
    "          inputs_embeds=None,\n",
    "\n",
    "          next_sentence_label=None,\n",
    "\n",
    "  ):\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    # input_ids 첫번째 입력(문장) 저장\n",
    "\n",
    "    input_ids_1 = input_ids[0]\n",
    "\n",
    "    # input_ids 첫번째 입력(문장)의 attention_mask 저장\n",
    "\n",
    "    attention_mask_1 = attention_mask[0]\n",
    "\n",
    "    # bert_model_1에 input_ids_1 투입한 결과를 outputs에 순차적으로 저장\n",
    "\n",
    "    outputs.append(self.bert_model_1(input_ids_1,\n",
    "\n",
    "                                     attention_mask=attention_mask_1))\n",
    "\n",
    "    # input_ids 두번째 입력(문장) 저장\n",
    "\n",
    "    input_ids_2 = input_ids[1]\n",
    "\n",
    "    # input_ids 두번째 입력(문장)의 attention_mask 저장\n",
    "\n",
    "    attention_mask_2 = attention_mask[1]\n",
    "\n",
    "    # bert_model_2에 input_ids_2 투입한 결과를 outputs에 순차적으로 저장\n",
    "\n",
    "    outputs.append(self.bert_model_2(input_ids_2,\n",
    "\n",
    "                                     attention_mask=attention_mask_2))\n",
    "\n",
    "    # torch.cat()로 텐서 병합\n",
    "\n",
    "    last_hidden_states = torch.cat([output[1] for output in outputs], dim=1)\n",
    "\n",
    "    logits = self.cls(last_hidden_states)\n",
    "\n",
    "    if next_sentence_label is not None:\n",
    "\n",
    "      loss_fct = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "      next_sentence_loss = loss_fct(logits.view(-1, 2), next_sentence_label.view(-1))\n",
    "\n",
    "      return next_sentence_loss, logits\n",
    "\n",
    "    else:\n",
    "\n",
    "      return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T12:57:12.167050Z",
     "end_time": "2023-08-24T12:57:12.185031Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# 로컬에서 실행할 경우 메모리 부족으로 cpu에서 실행\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# 모델 및 config 설정\n",
    "config = BertConfig()\n",
    "model = BertEnsembleForNextSentencePrediction(config)\n",
    "model.to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "learning_rate = 1e-5\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "\n",
    "# 최적화 함수 그룹 파라미터 설정\n",
    "optimizer_grouped_parameters = [{\n",
    "  \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "  }]\n",
    "\n",
    "# 최적화 함수 설정\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T12:57:14.490351Z",
     "end_time": "2023-08-24T12:57:17.297892Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "#데이터 증강 처리 함수\n",
    "# 질문-답변 문장을 답변-질문 순서로 바꿔서 추가\n",
    "\n",
    "def prepare_data(dataset, qa=True):\n",
    "  input_ids, attention_masks = [], []\n",
    "  labels = []\n",
    "  for point in dataset:\n",
    "    if qa is True:\n",
    "      # point에 있는 3개의 원소를 앞에 요소부터 q, a, _ 으로\n",
    "      q, a, _ = point\n",
    "    else:\n",
    "      # point에 있는 3개의 원소를 앞에 요소부터 a, q, _ 으로\n",
    "      a, q, _ = point\n",
    "    # q와 a를 토크나이저를 통해 인코딩\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "      q,  # 문장 1 인코딩\n",
    "      a,  # 문장 2 인코딩\n",
    "      add_special_tokens=True,  # 특수 토큰인 [CLS]와 [SEP] 생성\n",
    "      max_length=128,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,  # attention_mask 생성(패딩 처리된 부분은 1로 표시)\n",
    "      return_tensors='pt',\n",
    "      truncation=True\n",
    "    )\n",
    "    input_ids.append(encoded_dict[\"input_ids\"])\n",
    "    attention_masks.append(encoded_dict[\"attention_mask\"])\n",
    "    labels.append(point[-1])\n",
    "\n",
    "  # input_ids를 첫번째 축(dim=0), 즉 세로 방향으로 병합\n",
    "  input_ids = torch.cat(input_ids, dim=0)\n",
    "\n",
    "  # attention_mask를 첫번째 축(dim=0), 즉 세로 방향으로 병합\n",
    "  attention_masks = torch.cat(attention_masks, dim=0)\n",
    "  return input_ids, attention_masks, labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T12:57:18.155035Z",
     "end_time": "2023-08-24T12:57:18.173983Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, Dataset, SequentialSampler\n",
    "\n",
    "# QADataset 클래스 생성\n",
    "\n",
    "class QADataset(Dataset):\n",
    "\n",
    "  def __init__(self, input_ids, attention_masks, labels=None):\n",
    "    self.input_ids = np.array(input_ids)\n",
    "    self.attention_masks = np.array(attention_masks)\n",
    "    self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.input_ids[index], self.attention_masks[index], self.labels[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.input_ids.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T12:57:18.425998Z",
     "end_time": "2023-08-24T12:57:18.438963Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "input_ids_qa, attention_masks_qa, labels_qa = prepare_data(dataset)\n",
    "\n",
    "train_dataset_qa = QADataset(input_ids_qa, attention_masks_qa, labels_qa)\n",
    "\n",
    "input_ids_aq, attention_masks_aq, labels_aq = prepare_data(dataset, qa=False)\n",
    "\n",
    "train_dataset_aq = QADataset(input_ids_aq, attention_masks_aq, labels_aq)\n",
    "\n",
    "dataloader_qa =  DataLoader(dataset=train_dataset_qa,\n",
    "                            #batch_size=5,\n",
    "                            batch_size=1,\n",
    "                            sampler=SequentialSampler(train_dataset_qa))\n",
    "dataloader_aq =  DataLoader(dataset=train_dataset_aq,\n",
    "                            #batch_size=5,\n",
    "                            batch_size=1,\n",
    "                            sampler=SequentialSampler(train_dataset_aq))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T12:57:18.680746Z",
     "end_time": "2023-08-24T12:57:18.701720Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "7828"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T12:57:19.149776Z",
     "end_time": "2023-08-24T12:57:19.373313Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.0956\n",
      "epoch: 1, loss: 0.2618\n",
      "epoch: 1, loss: 1.3374\n",
      "epoch: 1, loss: 1.0743\n",
      "epoch: 1, loss: 0.2474\n",
      "epoch: 2, loss: 0.2099\n",
      "epoch: 2, loss: 0.3128\n",
      "epoch: 2, loss: 0.4954\n",
      "epoch: 2, loss: 0.5793\n",
      "epoch: 2, loss: 0.6046\n",
      "epoch: 3, loss: 0.3115\n",
      "epoch: 3, loss: 0.7186\n",
      "epoch: 3, loss: 0.3524\n",
      "epoch: 3, loss: 0.3091\n",
      "epoch: 3, loss: 0.5405\n"
     ]
    }
   ],
   "source": [
    "# 앙상블 학습 파인튜닝\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # dataloader와 dataloader_aq pair를 반복처리\n",
    "    for step, combined_batch in enumerate(zip(dataloader_qa, dataloader_aq)):\n",
    "        batch_1, batch_2 = combined_batch\n",
    "        model.train()\n",
    "\n",
    "        inputs = {\n",
    "            \"input_ids\" : [batch_1[0], batch_2[0]],\n",
    "            \"attention_mask\": [batch_1[1], batch_2[1]],\n",
    "            \"next_sentence_label\": batch_1[2]\n",
    "        }\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        print(f'epoch: {epoch+1}, loss: {loss:.4f}')\n",
    "        optimizer.step()\n",
    "        model.zero_grad()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T12:58:31.259517Z",
     "end_time": "2023-08-24T12:59:14.422028Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0, 1] [1, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트(학습용 데이터)\n",
    "\n",
    "input_ids_qa, attention_masks_qa, labels_qa = prepare_data(dataset)\n",
    "\n",
    "test_dataset_qa = QADataset(input_ids_qa, attention_masks_qa, labels_qa)\n",
    "\n",
    "input_ids_aq, attention_masks_aq, labels_aq = prepare_data(dataset, qa=False)\n",
    "\n",
    "test_dataset_aq = QADataset(input_ids_aq, attention_masks_aq, labels_aq)\n",
    "\n",
    "dataloader_qa =  DataLoader(dataset=test_dataset_qa,\n",
    "                            batch_size=16,\n",
    "                            sampler=SequentialSampler(test_dataset_qa))\n",
    "\n",
    "dataloader_aq =  DataLoader(dataset=test_dataset_aq,\n",
    "                            batch_size=16,\n",
    "                            sampler=SequentialSampler(test_dataset_aq))\n",
    "complete_outputs, complete_label_ids = [], []\n",
    "\n",
    "for step, combined_batch in enumerate(zip(dataloader_qa, dataloader_aq)):\n",
    "  model.eval()\n",
    "  batch_1, batch_2 = combined_batch\n",
    "  batch_1 = tuple(t.to(device) for t in batch_1)\n",
    "  batch_2 = tuple(t.to(device) for t in batch_2)\n",
    "  with torch.no_grad():\n",
    "\n",
    "    inputs = {\n",
    "        \"input_ids\": [batch_1[0], batch_2[0]],\n",
    "        \"attention_mask\": [batch_1[1], batch_2[1]],\n",
    "        \"next_sentence_label\": batch_1[2]\n",
    "    }\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    tmp_eval_loss, logits = outputs[:2]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    outputs = np.argmax(logits, axis=1)\n",
    "    label_ids = inputs[\"next_sentence_label\"].detach().cpu().numpy()\n",
    "  complete_outputs.extend(outputs)\n",
    "  complete_label_ids.extend(label_ids)\n",
    "\n",
    "print(complete_outputs, complete_label_ids)\n",
    "#예측과 실제값"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T13:05:53.093820Z",
     "end_time": "2023-08-24T13:05:54.887021Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [1]\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트(새로운 문장)\n",
    "\n",
    "dataset = [[\"What music do you like?\", \"I like Rock music.\", 1]]\n",
    "\n",
    "input_ids_qa, attention_masks_qa, labels_qa = prepare_data(dataset)\n",
    "test_dataset_qa = QADataset(input_ids_qa, attention_masks_qa, labels_qa)\n",
    "\n",
    "input_ids_aq, attention_masks_aq, labels_aq = prepare_data(dataset, qa=False)\n",
    "test_dataset_aq = QADataset(input_ids_aq, attention_masks_aq, labels_aq)\n",
    "\n",
    "dataloader_qa =  DataLoader(dataset=test_dataset_qa,\n",
    "                            batch_size=16,\n",
    "                            sampler=SequentialSampler(test_dataset_qa))\n",
    "\n",
    "dataloader_aq =  DataLoader(dataset=test_dataset_aq,\n",
    "                            batch_size=16,\n",
    "                            sampler=SequentialSampler(test_dataset_aq))\n",
    "\n",
    "complete_outputs, complete_label_ids = [], []\n",
    "\n",
    "for step, combined_batch in enumerate(zip(dataloader_qa, dataloader_aq)):\n",
    "  model.eval()\n",
    "  batch_1, batch_2 = combined_batch\n",
    "  batch_1 = tuple(t.to(device) for t in batch_1)\n",
    "  batch_2 = tuple(t.to(device) for t in batch_2)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    inputs = {\n",
    "        \"input_ids\": [batch_1[0], batch_2[0]],\n",
    "        \"attention_mask\": [batch_1[1], batch_2[1]],\n",
    "        \"next_sentence_label\": batch_1[2]\n",
    "    }\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    tmp_eval_loss, logits = outputs[:2]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    outputs = np.argmax(logits, axis=1)\n",
    "    label_ids = inputs[\"next_sentence_label\"].detach().cpu().numpy()\n",
    "\n",
    "  complete_outputs.extend(outputs)\n",
    "  complete_label_ids.extend(label_ids)\n",
    "\n",
    "print(complete_outputs, complete_label_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T13:07:11.616107Z",
     "end_time": "2023-08-24T13:07:11.951188Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
