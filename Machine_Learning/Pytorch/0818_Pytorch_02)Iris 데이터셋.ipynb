{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-08-18T12:18:03.636657Z",
     "end_time": "2023-08-18T12:18:03.658597Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "# iris 데이터셋 로딩\n",
    "X,y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X[:5])\n",
    "print(y[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T12:18:04.015644Z",
     "end_time": "2023-08-18T12:18:04.033594Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10, stratify=y,shuffle=True)\n",
    "print(len(X_train))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T12:18:04.331798Z",
     "end_time": "2023-08-18T12:18:04.355733Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "# 신경망 모형\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Model, self).__init__()\n",
    "        # input layer, Linear 선형함수(1차함수)\n",
    "        # input nodes, output nodes 50\n",
    "        self.layer1 = nn.Linear(input_dim, 50)\n",
    "        self.layer2 = nn.Linear(50, 20)\n",
    "        self.layer3 = nn.Linear(20,3)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        # 출력층의 활성화 함수 -> softmax\n",
    "        x = F.softmax(self.layer3(x))\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T12:18:04.631995Z",
     "end_time": "2023-08-18T12:18:04.657925Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "(120, 4)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T12:18:05.037910Z",
     "end_time": "2023-08-18T12:18:05.075808Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import torch\n",
    "model = Model(X_train.shape[1]) # 초기화함ㅅ수의 input_dim으로 변수개수가 전달됨\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) # 최적화함수 정의\n",
    "loss_fn = nn.CrossEntropyLoss() #손실함수 정의\n",
    "epochs = 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T12:18:05.367029Z",
     "end_time": "2023-08-18T12:18:05.393957Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "loss: 0.5701541304588318\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 2\n",
      "loss: 0.5701271295547485\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 3\n",
      "loss: 0.5701005458831787\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 4\n",
      "loss: 0.570074200630188\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 5\n",
      "loss: 0.5700494050979614\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 6\n",
      "loss: 0.5700269341468811\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 7\n",
      "loss: 0.5700124502182007\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 8\n",
      "loss: 0.5700122714042664\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 9\n",
      "loss: 0.5700727105140686\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 10\n",
      "loss: 0.5701878666877747\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 11\n",
      "loss: 0.5707085728645325\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 12\n",
      "loss: 0.5704312920570374\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 13\n",
      "loss: 0.570797324180603\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 14\n",
      "loss: 0.5701189637184143\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 15\n",
      "loss: 0.5699816942214966\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 16\n",
      "loss: 0.5699059963226318\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 17\n",
      "loss: 0.5700376629829407\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 18\n",
      "loss: 0.5702274441719055\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 19\n",
      "loss: 0.5712377429008484\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 20\n",
      "loss: 0.5698979496955872\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 21\n",
      "loss: 0.5696290731430054\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 22\n",
      "loss: 0.5697538256645203\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 23\n",
      "loss: 0.5703475475311279\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 24\n",
      "loss: 0.5723507404327393\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 25\n",
      "loss: 0.5698845386505127\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 26\n",
      "loss: 0.5789861083030701\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 27\n",
      "loss: 0.5765026807785034\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 28\n",
      "loss: 0.5903356671333313\n",
      "accuracy:  95.83333134651184 %\n",
      "Epoch 29\n",
      "loss: 0.5807110667228699\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 30\n",
      "loss: 0.5702890753746033\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 31\n",
      "loss: 0.6088211536407471\n",
      "accuracy:  94.16666626930237 %\n",
      "Epoch 32\n",
      "loss: 0.6107003688812256\n",
      "accuracy:  94.16666626930237 %\n",
      "Epoch 33\n",
      "loss: 0.5728833675384521\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 34\n",
      "loss: 0.5914987325668335\n",
      "accuracy:  95.83333134651184 %\n",
      "Epoch 35\n",
      "loss: 0.6045979261398315\n",
      "accuracy:  94.9999988079071 %\n",
      "Epoch 36\n",
      "loss: 0.604678750038147\n",
      "accuracy:  94.9999988079071 %\n",
      "Epoch 37\n",
      "loss: 0.5939714312553406\n",
      "accuracy:  94.9999988079071 %\n",
      "Epoch 38\n",
      "loss: 0.5729396939277649\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 39\n",
      "loss: 0.6112009882926941\n",
      "accuracy:  94.16666626930237 %\n",
      "Epoch 40\n",
      "loss: 0.6256187558174133\n",
      "accuracy:  91.66666865348816 %\n",
      "Epoch 41\n",
      "loss: 0.6200432181358337\n",
      "accuracy:  93.33333373069763 %\n",
      "Epoch 42\n",
      "loss: 0.5818604826927185\n",
      "accuracy:  96.66666388511658 %\n",
      "Epoch 43\n",
      "loss: 0.5939112901687622\n",
      "accuracy:  94.9999988079071 %\n",
      "Epoch 44\n",
      "loss: 0.6199595928192139\n",
      "accuracy:  93.33333373069763 %\n",
      "Epoch 45\n",
      "loss: 0.6212891936302185\n",
      "accuracy:  93.33333373069763 %\n",
      "Epoch 46\n",
      "loss: 0.5990502238273621\n",
      "accuracy:  94.9999988079071 %\n",
      "Epoch 47\n",
      "loss: 0.5754014253616333\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 48\n",
      "loss: 0.595630943775177\n",
      "accuracy:  94.9999988079071 %\n",
      "Epoch 49\n",
      "loss: 0.6001461744308472\n",
      "accuracy:  94.16666626930237 %\n",
      "Epoch 50\n",
      "loss: 0.5693973898887634\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 51\n",
      "loss: 0.5770983099937439\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 52\n",
      "loss: 0.5904185175895691\n",
      "accuracy:  95.83333134651184 %\n",
      "Epoch 53\n",
      "loss: 0.5881595611572266\n",
      "accuracy:  95.83333134651184 %\n",
      "Epoch 54\n",
      "loss: 0.5762355327606201\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 55\n",
      "loss: 0.5696555376052856\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 56\n",
      "loss: 0.5847827196121216\n",
      "accuracy:  96.66666388511658 %\n",
      "Epoch 57\n",
      "loss: 0.5692439675331116\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 58\n",
      "loss: 0.5746335983276367\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 59\n",
      "loss: 0.5759986639022827\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 60\n",
      "loss: 0.5761903524398804\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 61\n",
      "loss: 0.5756467580795288\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 62\n",
      "loss: 0.5734854340553284\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 63\n",
      "loss: 0.5695468187332153\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 64\n",
      "loss: 0.5740849375724792\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 65\n",
      "loss: 0.5705448389053345\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 66\n",
      "loss: 0.5726900696754456\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 67\n",
      "loss: 0.5703200101852417\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 68\n",
      "loss: 0.5726212859153748\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 69\n",
      "loss: 0.569255530834198\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 70\n",
      "loss: 0.5714412331581116\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 71\n",
      "loss: 0.5709352493286133\n",
      "accuracy:  97.50000238418579 %\n",
      "Epoch 72\n",
      "loss: 0.5697880983352661\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 73\n",
      "loss: 0.5701844692230225\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 74\n",
      "loss: 0.5702663660049438\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 75\n",
      "loss: 0.5704108476638794\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 76\n",
      "loss: 0.5694519281387329\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 77\n",
      "loss: 0.5698515176773071\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 78\n",
      "loss: 0.5698584914207458\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 79\n",
      "loss: 0.5697805881500244\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 80\n",
      "loss: 0.5696209669113159\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 81\n",
      "loss: 0.5691652894020081\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 82\n",
      "loss: 0.5697010159492493\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 83\n",
      "loss: 0.5691136717796326\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 84\n",
      "loss: 0.5698517560958862\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 85\n",
      "loss: 0.5688709616661072\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 86\n",
      "loss: 0.5694141983985901\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 87\n",
      "loss: 0.5688417553901672\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 88\n",
      "loss: 0.5691521167755127\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 89\n",
      "loss: 0.5690966844558716\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 90\n",
      "loss: 0.5688358545303345\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 91\n",
      "loss: 0.5692508220672607\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 92\n",
      "loss: 0.5687076449394226\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 93\n",
      "loss: 0.5688782334327698\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 94\n",
      "loss: 0.5688256621360779\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 95\n",
      "loss: 0.5685604214668274\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 96\n",
      "loss: 0.5687550902366638\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 97\n",
      "loss: 0.5685536861419678\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 98\n",
      "loss: 0.5685269236564636\n",
      "accuracy:  99.16666746139526 %\n",
      "Epoch 99\n",
      "loss: 0.5686227679252625\n",
      "accuracy:  98.33333492279053 %\n",
      "Epoch 100\n",
      "loss: 0.5684261918067932\n",
      "accuracy:  99.16666746139526 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjoeun\\AppData\\Local\\Temp\\ipykernel_10152\\42384072.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.layer3(x))\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "# 넘파일배열로부터 텐서를 ㅁ나들고\n",
    "# X_train = Variable(torch.from_numpy(X_train)).float()\n",
    "# y_train = Variable(torch.from_numpy(y_train)).long() # 정수형 데이터(주로 레이블이나 인덱스 다룰때 사용)\n",
    "\n",
    "# 2번째 할때부터\n",
    "X_train = X_train\n",
    "y_train = y_train\n",
    "for epoch in range(1, epochs+1):\n",
    "    print('Epoch', epoch)\n",
    "    # 예측값\n",
    "    y_pred = model(X_train)\n",
    "    # 손실함수에 예측값과 실제값을 입력\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    print('loss:', loss.item())\n",
    "\n",
    "    # 경사 초기화\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward() #역전파\n",
    "    optimizer.step() # 가중치 업데이트\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred_labels = torch.argmax(y_pred, dim=1) # 가장 높은 확률을 가진 클래스 선택\n",
    "        accuracy = (y_pred_labels == y_train).float().mean().item()\n",
    "        print('accuracy: ', accuracy * 100, '%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T12:20:23.713904Z",
     "end_time": "2023-08-18T12:20:23.908383Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[6.3000, 2.7000, 4.9000, 1.8000],\n        [5.8000, 2.6000, 4.0000, 1.2000],\n        [5.0000, 2.0000, 3.5000, 1.0000],\n        [4.8000, 3.4000, 1.6000, 0.2000],\n        [5.6000, 2.8000, 4.9000, 2.0000],\n        [6.5000, 3.0000, 5.2000, 2.0000],\n        [5.7000, 2.8000, 4.1000, 1.3000],\n        [6.0000, 2.7000, 5.1000, 1.6000],\n        [5.8000, 2.7000, 5.1000, 1.9000],\n        [5.6000, 3.0000, 4.1000, 1.3000],\n        [5.1000, 3.5000, 1.4000, 0.3000],\n        [5.7000, 3.0000, 4.2000, 1.2000],\n        [5.1000, 3.4000, 1.5000, 0.2000],\n        [6.5000, 3.2000, 5.1000, 2.0000],\n        [6.3000, 3.3000, 6.0000, 2.5000],\n        [6.7000, 3.1000, 4.7000, 1.5000],\n        [7.3000, 2.9000, 6.3000, 1.8000],\n        [4.8000, 3.0000, 1.4000, 0.3000],\n        [5.0000, 3.6000, 1.4000, 0.2000],\n        [6.6000, 3.0000, 4.4000, 1.4000],\n        [6.1000, 2.6000, 5.6000, 1.4000],\n        [6.9000, 3.1000, 5.4000, 2.1000],\n        [6.1000, 3.0000, 4.6000, 1.4000],\n        [5.0000, 3.5000, 1.3000, 0.3000],\n        [7.6000, 3.0000, 6.6000, 2.1000],\n        [5.0000, 3.4000, 1.5000, 0.2000],\n        [5.9000, 3.0000, 5.1000, 1.8000],\n        [6.5000, 3.0000, 5.8000, 2.2000],\n        [6.7000, 3.3000, 5.7000, 2.1000],\n        [4.9000, 2.5000, 4.5000, 1.7000],\n        [7.2000, 3.6000, 6.1000, 2.5000],\n        [4.8000, 3.0000, 1.4000, 0.1000],\n        [6.3000, 2.5000, 4.9000, 1.5000],\n        [5.5000, 2.3000, 4.0000, 1.3000],\n        [6.7000, 3.1000, 4.4000, 1.4000],\n        [7.7000, 2.8000, 6.7000, 2.0000],\n        [5.2000, 3.5000, 1.5000, 0.2000],\n        [4.7000, 3.2000, 1.3000, 0.2000],\n        [5.0000, 3.2000, 1.2000, 0.2000],\n        [6.9000, 3.1000, 4.9000, 1.5000],\n        [4.9000, 3.0000, 1.4000, 0.2000],\n        [5.3000, 3.7000, 1.5000, 0.2000],\n        [4.3000, 3.0000, 1.1000, 0.1000],\n        [4.4000, 3.0000, 1.3000, 0.2000],\n        [6.3000, 2.3000, 4.4000, 1.3000],\n        [7.9000, 3.8000, 6.4000, 2.0000],\n        [6.7000, 3.0000, 5.0000, 1.7000],\n        [5.7000, 2.9000, 4.2000, 1.3000],\n        [5.6000, 3.0000, 4.5000, 1.5000],\n        [5.4000, 3.7000, 1.5000, 0.2000],\n        [6.3000, 2.8000, 5.1000, 1.5000],\n        [5.9000, 3.2000, 4.8000, 1.8000],\n        [4.9000, 3.6000, 1.4000, 0.1000],\n        [6.8000, 3.0000, 5.5000, 2.1000],\n        [7.1000, 3.0000, 5.9000, 2.1000],\n        [6.4000, 3.2000, 5.3000, 2.3000],\n        [4.6000, 3.1000, 1.5000, 0.2000],\n        [5.2000, 2.7000, 3.9000, 1.4000],\n        [5.1000, 3.7000, 1.5000, 0.4000],\n        [7.7000, 2.6000, 6.9000, 2.3000],\n        [5.0000, 3.4000, 1.6000, 0.4000],\n        [7.7000, 3.0000, 6.1000, 2.3000],\n        [5.4000, 3.9000, 1.3000, 0.4000],\n        [5.4000, 3.4000, 1.5000, 0.4000],\n        [4.6000, 3.6000, 1.0000, 0.2000],\n        [6.7000, 3.1000, 5.6000, 2.4000],\n        [5.5000, 2.4000, 3.8000, 1.1000],\n        [5.1000, 3.3000, 1.7000, 0.5000],\n        [5.6000, 2.9000, 3.6000, 1.3000],\n        [6.2000, 2.9000, 4.3000, 1.3000],\n        [5.7000, 3.8000, 1.7000, 0.3000],\n        [5.5000, 2.4000, 3.7000, 1.0000],\n        [6.0000, 2.9000, 4.5000, 1.5000],\n        [6.4000, 3.2000, 4.5000, 1.5000],\n        [6.0000, 3.0000, 4.8000, 1.8000],\n        [5.6000, 2.5000, 3.9000, 1.1000],\n        [6.0000, 3.4000, 4.5000, 1.6000],\n        [4.8000, 3.4000, 1.9000, 0.2000],\n        [6.2000, 2.2000, 4.5000, 1.5000],\n        [6.9000, 3.2000, 5.7000, 2.3000],\n        [6.1000, 2.8000, 4.7000, 1.2000],\n        [5.4000, 3.4000, 1.7000, 0.2000],\n        [6.3000, 2.9000, 5.6000, 1.8000],\n        [6.3000, 3.3000, 4.7000, 1.6000],\n        [6.7000, 3.3000, 5.7000, 2.5000],\n        [5.8000, 2.7000, 4.1000, 1.0000],\n        [5.1000, 3.8000, 1.9000, 0.4000],\n        [6.3000, 3.4000, 5.6000, 2.4000],\n        [5.7000, 2.5000, 5.0000, 2.0000],\n        [6.1000, 2.8000, 4.0000, 1.3000],\n        [6.0000, 2.2000, 4.0000, 1.0000],\n        [6.4000, 3.1000, 5.5000, 1.8000],\n        [7.0000, 3.2000, 4.7000, 1.4000],\n        [5.5000, 2.5000, 4.0000, 1.3000],\n        [5.7000, 2.6000, 3.5000, 1.0000],\n        [6.4000, 2.7000, 5.3000, 1.9000],\n        [4.4000, 3.2000, 1.3000, 0.2000],\n        [4.5000, 2.3000, 1.3000, 0.3000],\n        [4.9000, 3.1000, 1.5000, 0.2000],\n        [4.8000, 3.1000, 1.6000, 0.2000],\n        [4.6000, 3.4000, 1.4000, 0.3000],\n        [6.7000, 2.5000, 5.8000, 1.8000],\n        [5.1000, 3.8000, 1.6000, 0.2000],\n        [7.4000, 2.8000, 6.1000, 1.9000],\n        [6.0000, 2.2000, 5.0000, 1.5000],\n        [6.7000, 3.0000, 5.2000, 2.3000],\n        [4.6000, 3.2000, 1.4000, 0.2000],\n        [5.5000, 4.2000, 1.4000, 0.2000],\n        [6.8000, 2.8000, 4.8000, 1.4000],\n        [5.2000, 4.1000, 1.5000, 0.1000],\n        [6.6000, 2.9000, 4.6000, 1.3000],\n        [7.2000, 3.0000, 5.8000, 1.6000],\n        [6.1000, 3.0000, 4.9000, 1.8000],\n        [6.1000, 2.9000, 4.7000, 1.4000],\n        [5.4000, 3.9000, 1.7000, 0.4000],\n        [5.8000, 2.8000, 5.1000, 2.4000],\n        [5.8000, 4.0000, 1.2000, 0.2000],\n        [6.4000, 2.8000, 5.6000, 2.1000],\n        [5.1000, 3.8000, 1.5000, 0.3000],\n        [5.9000, 3.0000, 4.2000, 1.5000]])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T12:19:24.941557Z",
     "end_time": "2023-08-18T12:19:24.992420Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjoeun\\AppData\\Local\\Temp\\ipykernel_10152\\42384072.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.layer3(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[6.2071e-06, 9.9992e-01, 7.1107e-05],\n        [9.9979e-01, 2.0849e-04, 4.6261e-12],\n        [8.4465e-06, 9.9660e-01, 3.3878e-03],\n        [2.9731e-06, 3.5829e-01, 6.4171e-01],\n        [2.0741e-03, 9.9793e-01, 2.9516e-07]], grad_fn=<SliceBackward0>)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "X_test = Variable(torch.from_numpy(X_test)).float()\n",
    "pred = model(X_test)\n",
    "pred[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T12:31:30.850326Z",
     "end_time": "2023-08-18T12:31:30.902187Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 2 1 2 0 2 2 0 0 1 2 2 1 0 0 1 2 0 2 2 2 0 0 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmax(pred.data.numpy(), axis=1)\n",
    "print(np.argmax(pred.data.numpy(), axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T12:31:31.012892Z",
     "end_time": "2023-08-18T12:31:31.042811Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# 모형의 정확도 측정\n",
    "accuracy_score(y_test, np.argmax(pred.data.numpy(), axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T12:31:31.124593Z",
     "end_time": "2023-08-18T12:31:31.159499Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "torch.save(model, \"c:/work/data/iris/iris-torch.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T12:31:31.301122Z",
     "end_time": "2023-08-18T12:31:31.338022Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjoeun\\AppData\\Local\\Temp\\ipykernel_10152\\42384072.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.layer3(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = torch.load(\"c:/work/data/iris/iris-torch.h5\")\n",
    "np.argmax(model2(X_test[0]).data.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T12:31:31.434763Z",
     "end_time": "2023-08-18T12:31:31.473659Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T12:31:32.178775Z",
     "end_time": "2023-08-18T12:31:32.192749Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjoeun\\AppData\\Local\\Temp\\ipykernel_10152\\42384072.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.layer3(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nModel                                    [32, 3]                   --\n├─Linear: 1-1                            [32, 50]                  250\n├─Linear: 1-2                            [32, 20]                  1,020\n├─Linear: 1-3                            [32, 3]                   63\n==========================================================================================\nTotal params: 1,333\nTrainable params: 1,333\nNon-trainable params: 0\nTotal mult-adds (M): 0.04\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.02\nParams size (MB): 0.01\nEstimated Total Size (MB): 0.02\n=========================================================================================="
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model)\n",
    "# input_size=(batch size, input nodes)\n",
    "\n",
    "summary(model, input_size=(32, 4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T12:31:32.498917Z",
     "end_time": "2023-08-18T12:31:32.535818Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nModel                                    --\n├─Linear: 1-1                            250\n├─Linear: 1-2                            1,020\n├─Linear: 1-3                            63\n=================================================================\nTotal params: 1,333\nTrainable params: 1,333\nNon-trainable params: 0\n================================================================="
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T12:31:32.635552Z",
     "end_time": "2023-08-18T12:31:32.651508Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
